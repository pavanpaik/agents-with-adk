[
  {
    "query": "Review this for performance issues:\n```python\ndef find_duplicates(items):\n    duplicates = []\n    for i in range(len(items)):\n        for j in range(i + 1, len(items)):\n            if items[i] == items[j] and items[i] not in duplicates:\n                duplicates.append(items[i])\n    return duplicates\n```",
    "expected_tool_use": [],
    "reference": {
      "must_detect": [
        {
          "type": "PERFORMANCE",
          "severity": "HIGH",
          "issue": "O(n²) algorithm where O(n) is possible",
          "current_complexity": "O(n²)",
          "optimal_complexity": "O(n)"
        }
      ],
      "must_suggest": ["set", "Counter", "O(n) solution"]
    }
  },
  {
    "query": "Review this database query pattern:\n```python\ndef get_user_posts(user_ids):\n    results = []\n    for user_id in user_ids:\n        user = User.query.get(user_id)\n        posts = Post.query.filter_by(user_id=user_id).all()\n        results.append({'user': user, 'posts': posts})\n    return results\n```",
    "expected_tool_use": [],
    "reference": {
      "must_detect": [
        {
          "type": "PERFORMANCE",
          "severity": "HIGH",
          "issue": "N+1 query problem",
          "impact": "1 + 2*N queries instead of 2"
        }
      ],
      "must_suggest": ["batch queries", "filter with in_", "prefetch_related"]
    }
  },
  {
    "query": "Review this string concatenation:\n```python\ndef build_html(items):\n    html = \"<ul>\"\n    for item in items:\n        html += f\"<li>{item}</li>\"\n    html += \"</ul>\"\n    return html\n```",
    "expected_tool_use": [],
    "reference": {
      "must_detect": [
        {
          "type": "PERFORMANCE",
          "severity": "MEDIUM",
          "issue": "String concatenation in loop is O(n²)",
          "current_complexity": "O(n²)",
          "optimal_complexity": "O(n)"
        }
      ],
      "must_suggest": ["join", "list"]
    }
  },
  {
    "query": "Review this memory inefficiency:\n```python\ndef process_large_file(filename):\n    with open(filename) as f:\n        lines = f.readlines()  # Loads entire file into memory\n\n    errors = []\n    for line in lines:\n        if 'ERROR' in line:\n            errors.append(line)\n    return errors\n```",
    "expected_tool_use": [],
    "reference": {
      "must_detect": [
        {
          "type": "PERFORMANCE",
          "severity": "HIGH",
          "issue": "Loading entire file into memory",
          "impact": "High memory usage for large files"
        }
      ],
      "must_suggest": ["generator", "iterate line by line", "yield"]
    }
  },
  {
    "query": "Review this list vs set usage:\n```python\nALLOWED_USERS = ['user1', 'user2', 'user3', ...]  # 10,000 users\n\ndef is_allowed(username):\n    return username in ALLOWED_USERS  # O(n) lookup\n```",
    "expected_tool_use": [],
    "reference": {
      "must_detect": [
        {
          "type": "PERFORMANCE",
          "severity": "MEDIUM",
          "issue": "Using list for membership testing",
          "current_complexity": "O(n)",
          "optimal_complexity": "O(1)"
        }
      ],
      "must_suggest": ["set", "O(1) lookup"]
    }
  },
  {
    "query": "Review this caching opportunity:\n```python\nclass Report:\n    def __init__(self, data):\n        self.data = data\n\n    @property\n    def summary(self):\n        # Expensive calculation\n        return expensive_analysis(self.data)\n\nreport = Report(data)\nprint(report.summary)\nprint(report.summary)  # Recalculates!\n```",
    "expected_tool_use": [],
    "reference": {
      "must_detect": [
        {
          "type": "PERFORMANCE",
          "severity": "MEDIUM",
          "issue": "Missing caching for expensive calculation",
          "impact": "Repeated expensive computations"
        }
      ],
      "must_suggest": ["cached_property", "lru_cache", "memoization"]
    }
  },
  {
    "query": "Review this I/O-bound task:\n```python\nimport requests\n\ndef fetch_urls(urls):\n    results = []\n    for url in urls:\n        response = requests.get(url)\n        results.append(response.json())\n    return results\n```",
    "expected_tool_use": [],
    "reference": {
      "must_detect": [
        {
          "type": "PERFORMANCE",
          "severity": "MEDIUM",
          "issue": "Sequential I/O operations",
          "impact": "Total time = sum of all request times"
        }
      ],
      "must_suggest": ["asyncio", "ThreadPoolExecutor", "concurrent"]
    }
  },
  {
    "query": "Review this efficient code (should have minimal findings):\n```python\nfrom functools import lru_cache\nfrom typing import List\n\n@lru_cache(maxsize=128)\ndef fibonacci(n: int) -> int:\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\ndef find_duplicates(items: List[int]) -> List[int]:\n    from collections import Counter\n    return [item for item, count in Counter(items).items() if count > 1]\n```",
    "expected_tool_use": [],
    "reference": {
      "must_detect": [],
      "should_not_flag": ["efficient", "optimized", "caching"],
      "max_findings": 0
    }
  }
]
